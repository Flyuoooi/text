{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d24920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/16\", device=device)\n",
    "\n",
    "image = preprocess(Image.open(\"2.jpg\")).unsqueeze(0).to(device) # CLIP.png为本文中图一，即CLIP的流程图\n",
    "text = clip.tokenize([\n",
    "    'a photo of a woman', \n",
    "    'a photo of a man', \n",
    "    'a photo of a pair of shoes', \n",
    "    'a photo of a car',\n",
    "    'a photo of a flower'\n",
    "]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image) # 将图片进行编码\n",
    "    text_features = model.encode_text(text)    # 将文本进行编码\n",
    "\n",
    "    image_features = F.normalize(image_features, p=2, dim=-1)\n",
    "    text_features = F.normalize(text_features, p=2, dim=-1)\n",
    "    \n",
    "    cosine_similarity = (image_features @ text_features.T).squeeze(0)\n",
    "    \n",
    "    logit_scale = model.logit_scale.exp()\n",
    "    scaled_logits = logit_scale * cosine_similarity\n",
    "    \n",
    "    probs = F.softmax(scaled_logits, dim=0).cpu().numpy()\n",
    "\n",
    "print(\"Cosine similarity scores:\", cosine_similarity.cpu().numpy())\n",
    "print(\"Label probs:\", probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632ff799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.CLIP import clip\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model, preprocess = clip.load(\"ViT-B/16\", device=device, jit=False)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560a2180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "import torch\n",
    "import types\n",
    "from PIL import Image\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 1) 加载 CLIP 模型（就是你 pip 装的那个）\n",
    "model, preprocess = clip.load(\"ViT-B/16\", device=device, jit=False)\n",
    "model.eval()\n",
    "\n",
    "# 2) 准备一个列表存所有层的注意力\n",
    "attn_maps = []\n",
    "\n",
    "# 3) 定义新的 attention 函数，替换 ResidualAttentionBlock.attention\n",
    "def attention_with_weights(self, x: torch.Tensor):\n",
    "    \"\"\"\n",
    "    x: [L, N, C]  (L = tokens, N = batch)\n",
    "    \"\"\"\n",
    "    # 保持原来的 mask 逻辑\n",
    "    if self.attn_mask is not None:\n",
    "        self.attn_mask = self.attn_mask.to(dtype=x.dtype, device=x.device)\n",
    "\n",
    "    # 关键：need_weights=True, average_attn_weights=False → 得到 [N, H, L, L]\n",
    "    out, weights = self.attn(\n",
    "        x, x, x,\n",
    "        need_weights=True,\n",
    "        attn_mask=self.attn_mask,\n",
    "        average_attn_weights=False,\n",
    "    )\n",
    "    # 保存注意力权重 (CPU 上存)\n",
    "    attn_maps.append(weights.detach().cpu())  # [N, heads, L, L]\n",
    "\n",
    "    return out\n",
    "\n",
    "# 4) 把视觉 Transformer 的所有 ResidualAttentionBlock.attention 替换掉\n",
    "# VisionTransformer 在 model.visual 里\n",
    "for block in model.visual.transformer.resblocks:\n",
    "    block.attention = types.MethodType(attention_with_weights, block)\n",
    "\n",
    "# 5) 跑一张图，触发前向 + 收集注意力\n",
    "img = preprocess(Image.open(\"1.jpg\")).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    _ = model.encode_image(img)   # 这里会走到我们改过的 attention()\n",
    "\n",
    "print(\"num layers:\", len(attn_maps))\n",
    "print(\"shape of one layer:\", attn_maps[0].shape)\n",
    "# 期望输出:\n",
    "# num layers: 12\n",
    "# shape of one layer: torch.Size([1, 12, 197, 197])\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 取最后一层的注意力\n",
    "attn_last = attn_maps[-1]          # [1, 12, 197, 197]\n",
    "attn_last = attn_last[0]           # [12, 197, 197]  heads, L, L\n",
    "\n",
    "# 平均所有 head\n",
    "attn_mean = attn_last.mean(0)      # [197, 197]\n",
    "\n",
    "# 取 CLS → patch 的注意力（CLS 是 token 0，patch 从 1 开始）\n",
    "cls_to_patches = attn_mean[0, 1:]          # [196]\n",
    "cls_to_patches = cls_to_patches.reshape(14, 14)  # 14x14 网格\n",
    "\n",
    "# 归一化到 [0,1]\n",
    "cls_norm = (cls_to_patches - cls_to_patches.min()) / (cls_to_patches.max() - cls_to_patches.min() + 1e-6)\n",
    "\n",
    "# 上采样到 224x224，方便和原图对齐\n",
    "heatmap = F.interpolate(\n",
    "    cls_norm.unsqueeze(0).unsqueeze(0),  # [1,1,14,14]\n",
    "    size=(224, 224),\n",
    "    mode=\"bilinear\",\n",
    "    align_corners=False\n",
    ").squeeze().numpy()\n",
    "\n",
    "# 可视化叠加\n",
    "orig = Image.open(\"2.jpg\").resize((224,224))\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(orig)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Original\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(orig)\n",
    "plt.imshow(heatmap, cmap=\"jet\", alpha=0.5)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"CLS→Patch Attention\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17ac3701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\envs\\CT\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "e:\\anaconda3\\envs\\CT\\lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'EasyCFG' object has no attribute 'DATA'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m view_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# 3) 构造模型\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmake_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcamera_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mview_num\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcuda()\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# 4) 读取 prompt learner\u001b[39;00m\n\u001b[0;32m     46\u001b[0m prompt_learner \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mprompt_learner\n",
      "File \u001b[1;32md:\\code\\text\\model\\backbone_prompt.py:733\u001b[0m, in \u001b[0;36mmake_model\u001b[1;34m(cfg, num_class, camera_num, view_num)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmake_model\u001b[39m(cfg, num_class, camera_num, view_num):\n\u001b[1;32m--> 733\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcamera_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mview_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32md:\\code\\text\\model\\backbone_prompt.py:413\u001b[0m, in \u001b[0;36mbuild_transformer.__init__\u001b[1;34m(self, num_classes, camera_num, view_num, cfg)\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv_embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;66;03m# ---- PromptLearner + TextEncoder ----\u001b[39;00m\n\u001b[1;32m--> 413\u001b[0m dataset_name \u001b[38;5;241m=\u001b[39m \u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDATA\u001b[49m\u001b[38;5;241m.\u001b[39mDATASET\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt_learner \u001b[38;5;241m=\u001b[39m PromptLearner(\n\u001b[0;32m    415\u001b[0m     num_classes,\n\u001b[0;32m    416\u001b[0m     dataset_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    419\u001b[0m     mask_prob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_prob,\n\u001b[0;32m    420\u001b[0m )\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_encoder \u001b[38;5;241m=\u001b[39m TextEncoder(clip_model)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'EasyCFG' object has no attribute 'DATA'"
     ]
    }
   ],
   "source": [
    "from model.CLIP import *\n",
    "import torch\n",
    "from model.backbone_prompt import make_model\n",
    "\n",
    "# 1) load CLIP\n",
    "clip_model, _ = clip.load(\"ViT-B/16\", device=\"cuda\")\n",
    "class EasyCFG:\n",
    "    class MODEL:\n",
    "        NAME = \"ViT-B/16\"\n",
    "        NECK = \"bnneck\"\n",
    "        COS_LAYER = False\n",
    "\n",
    "        # ---- SIE 配置 ----\n",
    "        SIE_CAMERA = False\n",
    "        SIE_VIEW = False\n",
    "        SIE_COE = 3.0 \n",
    "\n",
    "        # ---- 视觉编码器 stride ----\n",
    "        STRIDE_SIZE = (16, 16)\n",
    "\n",
    "        # ---- Prompt Mask ----\n",
    "        MASK_PROB = 0.2\n",
    "\n",
    "        # ---- CAA 残差校正 ----\n",
    "        CAA_GAMMA = 0.5\n",
    "\n",
    "    class INPUT:\n",
    "        SIZE_TRAIN = (256, 128)\n",
    "\n",
    "    class DATASETS:\n",
    "        NAMES = [\"LTCC\"]  \n",
    "\n",
    "    class TEST:\n",
    "        NECK_FEAT = \"after\"\n",
    "\n",
    "cfg = EasyCFG()\n",
    "\n",
    "num_class = 45\n",
    "camera_num = 1\n",
    "view_num = 1\n",
    "\n",
    "# 3) 构造模型\n",
    "model = make_model(cfg, num_class, camera_num, view_num).cuda().eval()\n",
    "\n",
    "# 4) 读取 prompt learner\n",
    "prompt_learner = model.prompt_learner\n",
    "\n",
    "print(\"cls_ctx shape:\", prompt_learner.cls_ctx.shape)\n",
    "print(\"prefix shape:\", prompt_learner.token_prefix.shape)\n",
    "print(\"suffix shape:\", prompt_learner.token_suffix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e7715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.backbone_prompt import PromptLearner\n",
    "prompts, readable = model.prompt_learner.visualize_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395d8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_readable = model.prompt_learner.visualize_masked_prompts(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40868b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from model.backbone_prompt import build_transformer\n",
    "\n",
    "text_emb = model.get_text_embeddings(masked=False)\n",
    "text_emb_mask = model.get_text_embeddings(masked=True)\n",
    "\n",
    "N = text_emb.shape[0]\n",
    "labels = np.arange(N)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sim = cosine_similarity(text_emb, text_emb_mask)\n",
    "plt.imshow(sim)\n",
    "plt.colorbar()\n",
    "\n",
    "\n",
    "# pca = PCA(n_components=2)\n",
    "# emb_pca = pca.fit_transform(text_emb)\n",
    "\n",
    "# # tsne = TSNE(n_components=2, perplexity=10, n_iter=2000)\n",
    "# # emb_tsne = tsne.fit_transform(text_emb)\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(6,5))\n",
    "# plt.scatter(emb_tsne[:,0], emb_tsne[:,1], c=labels, cmap='tab10', s=80)\n",
    "\n",
    "# for i in range(N):\n",
    "#     plt.text(emb_tsne[i,0], emb_tsne[i,1], f\"C{i}\", fontsize=9)\n",
    "\n",
    "# plt.title(\"PCA of Text Embeddings\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f8266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import torch\n",
    "\n",
    "# # ------------------------\n",
    "# # 1) 获取文本 embedding\n",
    "# # ------------------------\n",
    "# text_emb = model.get_text_embeddings(masked=False)   \n",
    "# text_emb_mask = model.get_text_embeddings(masked=True)\n",
    "\n",
    "# def to_numpy(x):\n",
    "#     if isinstance(x, torch.Tensor):\n",
    "#         return x.detach().cpu().numpy()\n",
    "#     elif isinstance(x, np.ndarray):\n",
    "#         return x\n",
    "#     else:\n",
    "#         raise ValueError(\"Unsupported type:\", type(x))\n",
    "\n",
    "# X1 = to_numpy(text_emb)\n",
    "# X2 = to_numpy(text_emb_mask)\n",
    "\n",
    "\n",
    "# C = X1.shape[0]\n",
    "\n",
    "# # ------------------------\n",
    "# # 2) 拼接用于 t-SNE\n",
    "# # ------------------------\n",
    "# X = np.concatenate([X1, X2], axis=0)  # (2C, 512)\n",
    "\n",
    "# # 标签：\n",
    "# labels = np.concatenate([\n",
    "#     np.arange(C),    # unmasked 类 ID\n",
    "#     np.arange(C)     # masked 同样类 ID\n",
    "# ])\n",
    "\n",
    "# domain = np.array([0]*C + [1]*C)  \n",
    "# # domain=0 → unmasked，domain=1 → masked\n",
    "\n",
    "# # ------------------------\n",
    "# # 3) t-SNE 降维\n",
    "# # ------------------------\n",
    "# tsne = TSNE(\n",
    "#     n_components=2,\n",
    "#     perplexity=15,\n",
    "#     learning_rate='auto',\n",
    "#     init='pca',\n",
    "#     max_iter=2000\n",
    "# )\n",
    "\n",
    "# X_tsne = tsne.fit_transform(X)  # (2C, 2)\n",
    "\n",
    "# # ------------------------\n",
    "# # 4) 绘图（论文级别）\n",
    "# # ------------------------\n",
    "# plt.figure(figsize=(8,7))\n",
    "\n",
    "# # unmasked\n",
    "# plt.scatter(\n",
    "#     X_tsne[:C,0], X_tsne[:C,1],\n",
    "#     c=labels[:C], cmap='tab20',\n",
    "#     marker='o', s=70, label=\"unmasked\"\n",
    "# )\n",
    "\n",
    "# # masked\n",
    "# plt.scatter(\n",
    "#     X_tsne[C:,0], X_tsne[C:,1],\n",
    "#     c=labels[C:], cmap='tab20',\n",
    "#     marker='x', s=70, label=\"masked\"\n",
    "# )\n",
    "\n",
    "# # 标注\n",
    "# for i in range(C):\n",
    "#     plt.text(X_tsne[i,0],     X_tsne[i,1],     f\"C{i}\", fontsize=8)\n",
    "#     plt.text(X_tsne[i+C,0],   X_tsne[i+C,1],   f\"C{i}\", fontsize=8)\n",
    "\n",
    "# plt.legend()\n",
    "# plt.title(\"t-SNE of Text Embeddings (unmasked vs masked)\", fontsize=15)\n",
    "# plt.grid(alpha=0.3)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# --- 1. numpy 处理 ---\n",
    "def to_numpy(x):\n",
    "    import torch\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.detach().cpu().numpy()\n",
    "    return x\n",
    "\n",
    "text_emb = to_numpy(model.get_text_embeddings(masked=False))\n",
    "text_emb_mask = to_numpy(model.get_text_embeddings(masked=True))\n",
    "\n",
    "C = text_emb.shape[0]\n",
    "\n",
    "# --- 2. 拼接 t-SNE 输入 ---\n",
    "X = np.concatenate([text_emb, text_emb_mask], axis=0)\n",
    "\n",
    "tsne = TSNE(\n",
    "    n_components=2,\n",
    "    perplexity=20,\n",
    "    init='pca',\n",
    "    learning_rate='auto',\n",
    "    max_iter=2000\n",
    ")\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "# --- 3. 分离 unmask / mask ---\n",
    "U = X_tsne[:C]\n",
    "M = X_tsne[C:]\n",
    "\n",
    "# --- 4. 画连线版本 ---\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for i in range(C):\n",
    "    # 连线\n",
    "    plt.plot([U[i,0], M[i,0]], [U[i,1], M[i,1]],\n",
    "             c='gray', alpha=0.5, linewidth=1)\n",
    "    \n",
    "    # unmasked ●\n",
    "    plt.scatter(U[i,0], U[i,1],\n",
    "                c='blue', s=40)\n",
    "    \n",
    "    # masked ×\n",
    "    plt.scatter(M[i,0], M[i,1],\n",
    "                c='red', marker='x', s=40)\n",
    "\n",
    "plt.title(\"t-SNE with Line Connections (unmasked → masked)\", fontsize=16)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dacaa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def to_numpy(x):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.detach().cpu().numpy()\n",
    "    elif isinstance(x, np.ndarray):\n",
    "        return x\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported type:\", type(x))\n",
    "\n",
    "# 1) 获取 embedding\n",
    "text_emb = to_numpy(model.get_text_embeddings(masked=False))   # (C, 512)\n",
    "text_emb_mask = to_numpy(model.get_text_embeddings(masked=True))\n",
    "\n",
    "C = text_emb.shape[0]\n",
    "\n",
    "# 2) 用 unmasked 训练 PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(text_emb)\n",
    "\n",
    "U = pca.transform(text_emb)        # unmasked in 2D, (C, 2)\n",
    "M = pca.transform(text_emb_mask)   # masked in SAME PCA space\n",
    "\n",
    "# 3) 画箭头图\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for i in range(C):\n",
    "    # 箭头：unmasked -> masked\n",
    "    plt.arrow(\n",
    "        U[i,0], U[i,1],\n",
    "        M[i,0]-U[i,0], M[i,1]-U[i,1],\n",
    "        length_includes_head=True,\n",
    "        head_width=0.15, head_length=0.3,\n",
    "        fc='gray', ec='gray', alpha=0.6\n",
    "    )\n",
    "    # 起点：unmasked\n",
    "    plt.scatter(U[i,0], U[i,1], c='blue', s=40)\n",
    "    # 终点：masked\n",
    "    plt.scatter(M[i,0], M[i,1], c='red', marker='x', s=40)\n",
    "\n",
    "plt.title(\"PCA of Text Embeddings with Arrows (unmasked → masked)\", fontsize=16)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a64f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "text = model.get_text_embeddings(masked=False)\n",
    "text_m = model.get_text_embeddings(masked=True)\n",
    "\n",
    "# ---- 计算真实变化（高维） ----\n",
    "cos_sim = np.sum(text * text_m, axis=1) / (\n",
    "    np.linalg.norm(text,axis=1) * np.linalg.norm(text_m,axis=1)\n",
    ")\n",
    "\n",
    "shift = 1 - cos_sim     # 真实余弦距离变化\n",
    "print(\"mean perturbation:\", shift.mean())\n",
    "print(\"max perturbation:\", shift.max())\n",
    "print(\"min perturbation:\", shift.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be98524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import cfg\n",
    "print(cfg.MODEL.DEVICE_ID, type(cfg.MODEL.DEVICE_ID))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e1193f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 确保能 import 你工程\n",
    "PROJ_ROOT = \"/home/jin/code/text\"\n",
    "if PROJ_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJ_ROOT)\n",
    "\n",
    "YML_PATH   = \"/home/jin/code/text/configs/last/ViT-16.yml\"\n",
    "CKPT_PATH  = \"/home/jin/code/text/logs/vit16_last/model_best.pth\"  # 例如: \"\"；为空则不加载\n",
    "\n",
    "DEVICE_ID = 0\n",
    "device = torch.device(f\"cuda:{DEVICE_ID}\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06fdfead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE_ATTN_MASK = True ATTN_MASK_RATIO = 0.5\n",
      "INPUT.SIZE_TRAIN = (256, 128)\n"
     ]
    }
   ],
   "source": [
    "from yacs.config import CfgNode as CN\n",
    "\n",
    "def _ensure(cfg, key, value):\n",
    "    parts = key.split(\".\")\n",
    "    node = cfg\n",
    "    for p in parts[:-1]:\n",
    "        if p not in node:\n",
    "            node[p] = CN()\n",
    "        node = node[p]\n",
    "    if parts[-1] not in node:\n",
    "        node[parts[-1]] = value\n",
    "\n",
    "def load_cfg_like_train(yml_path):\n",
    "    \"\"\"\n",
    "    尽量复现 train.py 的 cfg 构建方式：defaults -> merge yml -> freeze\n",
    "    \"\"\"\n",
    "    cfg = None\n",
    "\n",
    "    # 你工程常见的几种 defaults 入口（逐个尝试）\n",
    "    tried = []\n",
    "    for mod, attr in [\n",
    "        (\"config.defaults\", \"get_cfg_defaults\"),\n",
    "        (\"configs.defaults\", \"get_cfg_defaults\"),\n",
    "        (\"config\", \"cfg\"),\n",
    "        (\"configs\", \"cfg\"),\n",
    "    ]:\n",
    "        try:\n",
    "            m = __import__(mod, fromlist=[attr])\n",
    "            obj = getattr(m, attr)\n",
    "            cfg = obj() if callable(obj) else obj.clone()\n",
    "            break\n",
    "        except Exception as e:\n",
    "            tried.append((mod, attr, str(e)))\n",
    "\n",
    "    # fallback：没有 defaults 时用空 cfg，但会补齐关键字段避免 AttributeError\n",
    "    if cfg is None:\n",
    "        cfg = CN(new_allowed=True)\n",
    "\n",
    "    cfg.merge_from_file(yml_path)\n",
    "\n",
    "    # 兜底补字段（避免 notebook 场景缺字段）\n",
    "    _ensure(cfg, \"MODEL.COS_LAYER\", False)\n",
    "    _ensure(cfg, \"MODEL.NECK\", \"bnneck\")\n",
    "    _ensure(cfg, \"TEST.NECK_FEAT\", \"after\")\n",
    "    _ensure(cfg, \"MODEL.DIST_TRAIN\", False)\n",
    "\n",
    "    # 你现在要可视化 attn-guided mask：这里强制打开（不影响你训练代码，只是 notebook 可视化）\n",
    "    cfg.defrost()\n",
    "    _ensure(cfg, \"MODEL.USE_ATTN_MASK\", True)\n",
    "    _ensure(cfg, \"MODEL.ATTN_MASK_RATIO\", 0.5)  # 你想 mask 的比例\n",
    "    _ensure(cfg, \"MODEL.MASK_PROB\", 1.0)        # notebook 可视化可设 1.0，保证每次都触发（训练时你自己再改回去）\n",
    "    cfg.MODEL.USE_ATTN_MASK = True\n",
    "    cfg.freeze()\n",
    "\n",
    "    return cfg\n",
    "\n",
    "cfg = load_cfg_like_train(YML_PATH)\n",
    "print(\"USE_ATTN_MASK =\", cfg.MODEL.USE_ATTN_MASK, \"ATTN_MASK_RATIO =\", cfg.MODEL.ATTN_MASK_RATIO)\n",
    "print(\"INPUT.SIZE_TRAIN =\", cfg.INPUT.SIZE_TRAIN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2770f7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jin/miniconda3/envs/CT/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/jin/miniconda3/envs/CT/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for build_transformer:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([5000, 768]) from checkpoint, the shape in current model is torch.Size([221, 768]).\n\tsize mismatch for classifier_proj.weight: copying a param with shape torch.Size([5000, 512]) from checkpoint, the shape in current model is torch.Size([221, 512]).\n\tsize mismatch for prompt_learner.cls_ctx: copying a param with shape torch.Size([5000, 16, 512]) from checkpoint, the shape in current model is torch.Size([221, 16, 512]).\n\tsize mismatch for prompt_learner.cls_ctx_init: copying a param with shape torch.Size([5000, 16, 512]) from checkpoint, the shape in current model is torch.Size([221, 16, 512]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(CKPT_PATH, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m state \u001b[38;5;241m=\u001b[39m ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, ckpt)  \u001b[38;5;66;03m# 兼容你保存的是 {\"model\":...} 或直接 state_dict\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m missing, unexpected \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaded ckpt:\u001b[39m\u001b[38;5;124m\"\u001b[39m, CKPT_PATH)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(missing), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munexpected:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(unexpected))\n",
      "File \u001b[0;32m~/miniconda3/envs/CT/lib/python3.10/site-packages/torch/nn/modules/module.py:2624\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2616\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2617\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2618\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2619\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2620\u001b[0m             ),\n\u001b[1;32m   2621\u001b[0m         )\n\u001b[1;32m   2623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2624\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2625\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2626\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2627\u001b[0m         )\n\u001b[1;32m   2628\u001b[0m     )\n\u001b[1;32m   2629\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for build_transformer:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([5000, 768]) from checkpoint, the shape in current model is torch.Size([221, 768]).\n\tsize mismatch for classifier_proj.weight: copying a param with shape torch.Size([5000, 512]) from checkpoint, the shape in current model is torch.Size([221, 512]).\n\tsize mismatch for prompt_learner.cls_ctx: copying a param with shape torch.Size([5000, 16, 512]) from checkpoint, the shape in current model is torch.Size([221, 16, 512]).\n\tsize mismatch for prompt_learner.cls_ctx_init: copying a param with shape torch.Size([5000, 16, 512]) from checkpoint, the shape in current model is torch.Size([221, 16, 512])."
     ]
    }
   ],
   "source": [
    "from model.backbone_prompt import make_model\n",
    "\n",
    "# PRCC 的 num_classes/cam/view 你自己按真实值填；只用于构建分类头维度\n",
    "NUM_CLASS = 221  # PRCC 常见 221（如果你不确定，先填你训练时的 num_classes）\n",
    "CAM_NUM   = 2\n",
    "VIEW_NUM  = 1\n",
    "\n",
    "model = make_model(cfg, NUM_CLASS, CAM_NUM, VIEW_NUM).to(device)\n",
    "model.eval()\n",
    "\n",
    "if CKPT_PATH and os.path.isfile(CKPT_PATH):\n",
    "    ckpt = torch.load(CKPT_PATH, map_location=\"cpu\")\n",
    "    state = ckpt.get(\"model\", ckpt)  # 兼容你保存的是 {\"model\":...} 或直接 state_dict\n",
    "    missing, unexpected = model.load_state_dict(state, strict=False)\n",
    "    print(\"loaded ckpt:\", CKPT_PATH)\n",
    "    print(\"missing:\", len(missing), \"unexpected:\", len(unexpected))\n",
    "else:\n",
    "    print(\"no ckpt loaded (CKPT_PATH empty or not found)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5327efb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataloader not used, fallback to random image. reason: ImportError('attempted relative import with no known parent package')\n",
      "using img: (1, 3, 256, 128) pid: 0\n"
     ]
    }
   ],
   "source": [
    "img = None\n",
    "pid = None\n",
    "\n",
    "# 1) 尝试从你的工程 dataloader 里拿一张（如果 import 路径不一致会自动跳过）\n",
    "try:\n",
    "    from .data.dataloader import make_dataloader  # 你工程常见命名，若不同你自己改一下\n",
    "    train_loader, _, num_query, num_classes, camera_num, view_num = make_dataloader(cfg)\n",
    "    batch = next(iter(train_loader))\n",
    "    # 你工程 batch 可能是 (img, pid, camid, viewid, ...) 或 dict，下面做兼容\n",
    "    if isinstance(batch, (list, tuple)):\n",
    "        img = batch[0]\n",
    "        pid = batch[1]\n",
    "    elif isinstance(batch, dict):\n",
    "        img = batch[\"img\"]\n",
    "        pid = batch[\"pid\"]\n",
    "    print(\"loaded a real batch from dataloader:\", img.shape, pid.shape)\n",
    "except Exception as e:\n",
    "    print(\"dataloader not used, fallback to random image. reason:\", repr(e))\n",
    "\n",
    "# 2) fallback：随机图（尺寸对齐你的训练输入）\n",
    "if img is None:\n",
    "    H, W = cfg.INPUT.SIZE_TRAIN\n",
    "    img = torch.randn(1, 3, H, W)\n",
    "    pid = torch.zeros(1, dtype=torch.long)\n",
    "\n",
    "# 只取 1 张做可视化\n",
    "img = img[:1].to(device)\n",
    "pid = pid[:1].to(device).long()\n",
    "print(\"using img:\", tuple(img.shape), \"pid:\", pid.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5ffb250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LaST attn-guided text mask] ctx_len=16, masked=8/16, mask_ratio=0.500\n",
      "CTX: <CTX-0> <MASK> <CTX-2> <MASK> <MASK> <CTX-5> <CTX-6> <CTX-7> <MASK> <CTX-9> <MASK> <MASK> <CTX-12> <CTX-13> <MASK> <MASK>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masked token norm(after)  min/mean/max: 0.0 0.22954614 0.48575124\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def visualize_attn_guided_text_mask(model, pid, img, title=\"attn-guided mask\"):\n",
    "    \"\"\"\n",
    "    可视化：\n",
    "    - ctx_attn 分数（prefix/suffix 不画，只画 cls_ctx）\n",
    "    - 被 mask 的 ctx token（top-k）\n",
    "    - 打印 prompt 结构（<CTX-i> / <MASK>）\n",
    "    \"\"\"\n",
    "    pl = model.prompt_learner\n",
    "\n",
    "    # 1) 生成未 mask 的 prompts\n",
    "    prompts = pl(pid, mask_mode=\"none\")  # [B,L,C]\n",
    "\n",
    "    # 2) 用图像特征引导 mask（用 feat_proj，与你 forward 中一致）\n",
    "    _, _, _, feat_proj = model.dummy_forward_image(img)  # 返回 img_feature, img_feature_proj, feat, feat_proj\n",
    "    prompts_masked, attn, mask_bool = model.apply_attn_guided_mask(prompts, feat_proj)\n",
    "\n",
    "    prefix_len = pl.token_prefix.shape[1]\n",
    "    ctx_len    = pl.cls_ctx.shape[1]\n",
    "    suffix_len = pl.token_suffix.shape[1]\n",
    "\n",
    "    ctx_attn = attn[0, prefix_len:prefix_len+ctx_len].float().cpu().numpy()\n",
    "    ctx_mask = mask_bool[0, prefix_len:prefix_len+ctx_len].bool().cpu().numpy()\n",
    "    mask_ratio = float(ctx_mask.mean())\n",
    "\n",
    "    # 3) 打印结构（只打印 ctx 部分更直观）\n",
    "    readable = []\n",
    "    for i in range(ctx_len):\n",
    "        readable.append(\"<MASK>\" if ctx_mask[i] else f\"<CTX-{i}>\")\n",
    "    print(f\"[{title}] ctx_len={ctx_len}, masked={ctx_mask.sum()}/{ctx_len}, mask_ratio={mask_ratio:.3f}\")\n",
    "    print(\"CTX:\", \" \".join(readable))\n",
    "\n",
    "    # 4) 画图：注意力分数 + mask 标记\n",
    "    x = np.arange(ctx_len)\n",
    "\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.bar(x, ctx_attn)\n",
    "    plt.title(f\"{title} | ctx attention (pid={int(pid.item())})\")\n",
    "    plt.xlabel(\"ctx token index\")\n",
    "    plt.ylabel(\"cos(attn) score\")\n",
    "\n",
    "    # 用红圈标出被 mask 的 token\n",
    "    masked_idx = np.where(ctx_mask)[0]\n",
    "    plt.scatter(masked_idx, ctx_attn[masked_idx], s=80, marker=\"o\")\n",
    "    plt.show()\n",
    "\n",
    "    # 5) sanity check：mask 后 token 是否真的被置零（只查 ctx 区域）\n",
    "    ctx_before = prompts[0, prefix_len:prefix_len+ctx_len].float()\n",
    "    ctx_after  = prompts_masked[0, prefix_len:prefix_len+ctx_len].float()\n",
    "    # 被 mask 的 token 向量范数应接近 0\n",
    "    norm_after = ctx_after.norm(dim=-1).cpu().numpy()\n",
    "    print(\"masked token norm(after)  min/mean/max:\", norm_after.min(), norm_after.mean(), norm_after.max())\n",
    "\n",
    "    return {\n",
    "        \"attn_ctx\": ctx_attn,\n",
    "        \"mask_ctx\": ctx_mask,\n",
    "        \"mask_ratio\": mask_ratio,\n",
    "        \"prompts\": prompts,\n",
    "        \"prompts_masked\": prompts_masked,\n",
    "        \"attn_full\": attn,\n",
    "        \"mask_full\": mask_bool,\n",
    "    }\n",
    "\n",
    "out = visualize_attn_guided_text_mask(model, pid, img, title=\"LaST attn-guided text mask\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da5e069e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m root \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/jin/code/text/data/Data/ReIDData\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m prcc \u001b[38;5;241m=\u001b[39m PRCC(root\u001b[38;5;241m=\u001b[39mroot, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 10\u001b[0m train_set \u001b[38;5;241m=\u001b[39m ImageDataset(prcc\u001b[38;5;241m.\u001b[39mtrain, \u001b[43mprcc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcamid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     11\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_set, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     13\u001b[0m imgs, pids, camids, clothes_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "from data.datasets.prcc import PRCC\n",
    "from data.dataset_loader import ImageDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "# === 1. 构建数据集 & dataloader，拿一小批就够了 ===\n",
    "root = \"/home/jin/code/text/data/Data/ReIDData\"\n",
    "prcc = PRCC(root=root, verbose=True)\n",
    "train_set = ImageDataset(prcc.train, prcc.train[0]['camid'])\n",
    "train_loader = DataLoader(train_set, batch_size=8, shuffle=True, num_workers=0)\n",
    "\n",
    "imgs, pids, camids, clothes_ids = next(iter(train_loader))\n",
    "\n",
    "# === 2. 前向一次，打开 return_dict & debug ===\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(\n",
    "        x=imgs.to(device),\n",
    "        label=pids.to(device),\n",
    "        cam_label=camids.to(device),\n",
    "        clothes_id=clothes_ids.to(device),\n",
    "        return_dict=True,\n",
    "        debug=True,          # 这样才会存 attn_scores / ctx_mask / coop_debug\n",
    "    )\n",
    "\n",
    "# 把需要的字段取出来\n",
    "attn      = outputs[\"attn_scores\"]      # [B, L]\n",
    "mask_bool = outputs[\"ctx_mask\"].bool()  # [B, L]\n",
    "pids_np   = pids.cpu().numpy()\n",
    "print(attn.shape, mask_bool.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
